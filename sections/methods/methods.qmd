---
title: Methods
output-file: index
header-includes:
  - \setcounter{page}{4}  
---

## Physical Construction{#physical-construction}
The OpenIVIS box is made out of laser cut acrylic and 3D printed parts. Black acrylic was cut to form the base, back, and sides of the box. The acrylic pieces have extruding parts along their rims to connect in a jigsaw puzzle configuration. This ensures that no light can leak out of the box and that the box is stable. The front of the box is made from a 3D printed PLA filament and has long notches to allow for the black acrylic door to slide up and down. Fig. 4.1 shows the fully assembled box (a) and the inside of the box (b) where subjects under test are placed.

![Fig. 4.1 Image of assembled box (a) and inside of the box (b)](./images/FullBox.png)

The box has two replaceable lids for the different imaging methods.The first lid is designed for laser speckle contrast imaging. The lid is made out of black acrylic with three holes cut into it. One hole holds the camera while the other two holes hold the laser diode configuration described in Section 2.2. Fig. 4.2 shows the assembly used for LSCI.

![Fig. 4.2 Image of Assembled Box](./images/LaserLid.png)

The second lid is designed for fluorescence imaging. It has an upper layer of black acrylic jigsaw pieces. On the underside of the lid is a 3D printed ring to hold an array of Neopixel LEDs. Beneath the LED array is a diffusion plate made of white acrylic to allow for the LEDs to shine through and into the box. A 3D print   ed camera holder is secured to the white acrylic and has space for a 3D printed optical filter holder to slide in beneath the camera. Fig. 4.3 shows the fully assembled fluorescence top and LED array. This configuration can also be used for other imaging methods that implement the Neopixel LED array, as discussed in Section 4.3.4.

![Fig. 4.3 Image of the fluorescence lid (a) and the lid with the LED array (b)](./images/FITCConfig.png)

## Electrical Components and Software {#electrical-components-and-software}
The OpenIVIS system runs primarily off of a Raspberry Pi 4, and other cheap, off-the-shelf electronics. The Raspberry Pi is a series of small single-board computers developed to be an educational tool, which has many interfacing options such as general purpose input/output pins (GPIO) that can connect to sensors. The camera used for all images in this project is an Arducam IMX519 color camera with a 24” flex cable, which is Raspberry Pi compatible and has autofocus features. A desktop and mouse are connected to the USB interfaces of the Raspberry Pi in order to use the system and make any necessary alterations. The system is stored on a 128 GB microSD card with the appropriate Raspberry Pi operating system.

For most imaging methods used by the OpenIVIS system, an LED array of Adafruit Neopixel RGB LED modules is used to illuminate subjects under study. In order to connect to the Raspberry Pi, a Raspberry Pi prototyping board is wired along with a logic level converter and terminal block as shown in Fig. 4.4, as well as powered by an external 5V power supply. The LED array is connected to the pulse width modulated (PWM) pin from the Raspberry Pi to provide control. The LED’s are affixed to the 3D printed LED array as described in section 2.1. Unmounted, 25 mm thick long-pass optical glass filters were sourced from Thorlabs in cutoff  wavelengths of 515 nm, 570 nm, 665 nm and 695 nm.

![Fig. 4.4: Raspberry Pi Prototyping board schematic with the breakout board (a), header pins (b), logic level converter (c), DC audio jack (d), and 3 pin terminal block (e)](./images/LEDSchematic.png)


LSCI and other laser based imaging techniques implement a red ThorLabs 635 nm Collimated Laser Diode Module, along with Thorlabs’ [RA90](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1985&pn=RA90), [SM1TC](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1533&pn=SM1TC#5063), [SM1D12D](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1479&pn=SM1D12D#5409), [GBE05-A](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1580&pn=GBE05-A), [LDS5](https://www.thorlabs.com/thorproduct.cfm?partnumber=LDS5&pn=LDS5), [TR3](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1266&pn=TR3#237), [TR6](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1266&pn=TR3#237), [CPS635R](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=1487&pn=CPS635R#1620), [SM1S10](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=3307&pn=SM1S10#5039), [SM1T1](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=2704&pn=SM1T1#1526) and [AD11F](https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=219&pn=AD11F#367) to properly configure the laser beam. The laser configuration as shown in Fig. 4.5a is affixed to the lid of the OpenIVIS box using a  3/8” 1/4-20 bolt, as shown in Fig. 4.5b. 

![Fig. 4.5 The laser diode configuration (a) and laser imaging setup (b) ](./images/LaserConfig.png)

The majority of the code used to run the OpenIVIS system is written in the programming language Python, and available in the project’s public GitHub repository @openIVIS2024. Descriptions of the Python scripts necessary to collect and process data are described in the repository's “Read Me” file. The list of necessary Python Packages is listed in Appendix 2, and is run on the Raspberry Pi through a virtual environment. The Neopixel LED array and Arducam camera Python libraries are also used and require installation. Additional data processing code was written using Mathworks’ MatLab software. 

A full list of materials, code, and relevant CAD files is available in Appendix 1, Appendix 3 and Appendix 4, respectively.


## Experiments {#experiments}

###  Verification {#verification}
Before fluorescence and laser speckle contrast imaging, it was necessary to verify that the Arducam camera and the LED lights were working properly. The Neopixel Python library allows for brightness control in two forms. The first is through changing the brightness level of the LED output, which can be set to any value between 0 and 1 arbitrary units. In addition to brightness level, the usage of 4 valued color codes allow for the user to change both the color of the LED output and the brightness of each color. The red, green, blue and white brightness values range from 0 to 255 arbitrary units. 

Brightness level and exposure time verification can be done by changing the exposure time of the camera while keeping the brightness constant and by changing the brightness level of the LEDs while keeping the exposure time constant. The exposure time, or shutter speed, controls how long the camera is exposed to light when taking an image, and it is controlled using picamera2 settings. The brightness level of the LEDs is controlled using the NeoPixel library settings. Images were taken at full brightness and varying exposure times of 0.001, 0.005, 0.01, 0.05, and 0.1 seconds. Images were also taken at exposure times of 0.01 and 0.1 seconds with varying brightness levels from 0 to 1 arbitrary units. These settings for these images were then compared to the intensities of the pixels in the images. 

The pixel intensities were measured by taking a three by three set of pixels near the center of the image and putting them in an excel spreadsheet. To plot the data a MATLAB script was used to read in the intensity values and average across each set of nine. These averaged values were then averaged across five different trials of varying the brightness level and exposure time. The expected results are positive trends between exposure time and pixel intensity and brightness level and pixel intensity.

Since the above process will only verify the LEDs based on what the camera is detecting from the LED light, it was also necessary to test the actual LED output using a photodiode. The photodiode outputs wattage values based on the intensity of light detected. Changing both the brightness levels from the NeoPixel settings and the color code values of the red, green, blue, and white LEDs should result in positive trends between brightness value and output wattage. The photodiode was placed inside of the system’s main box compartment with the sensor facing upward. Data was collected for three different sensor locations in the box. For each location, a Python script was used to cycle through the Neopixel brightness levels from 0 to 1, increasing by 0.1 each time to achieve 11 equally distributed brightness levels. For each brightness level, the color code tuples were also cycled from 0 to 255 for each LED color. The color code values increased by 26 a.u. each cycle to achieve 11 equality distributed values. The LED output in nW was saved in a spreadsheet for each setting, resulting in XXX values for each photodiode sensor location. The trends in the white LED output were analyzed for changes in brightness level at a constant color code of 255 a.u., and the changes in color code for a constant brightness level of 1. For each setting, the average wattage and standard deviation was taken across the three trials and inputted into a MatLab script that created graphs of those values across changes in Neopixel setting. 

All of the system verification experiments utilized the fluorescence imaging setup shown in Fig. 4.3


### Fluorescein Isothiocyanate {#fitc}

To test the fluorescence capabilities of OpenIVIS, ten concentrations of the commonly used fluorescent dye, Fluorescein isothiocyanate (FITC), were diluted in ethanol. FITC emits fluorescence of wavelengths ranging in the green spectrum with a peak around 530 nm [ThermoFisher]. To excite the FITC solutions, blue LEDs were used to illuminate the dye at full brightness. The Neopixel blue spectrum has a peak approximately 450 nm. To prevent the camera from detecting the excitation light, a 515 nm long pass optical filter was placed in front of the camera. The filter blocked out all wavelengths lower than 515 nm, including the blue excitation light. The ten different concentrations of FITC ranged from 10-3 M to 10-12 M. In a 96-well PCR plate, 2 wells of each FITC concentration were placed in a four by five orientation and put into the OpenIVIS box for imaging. 

To quantify the fluorescence of each FITC concentration, the raw image data from the captured images was converted into Bayer images. The Bayer images have a red, green, green, blue (RGGB) color filter array as shown in Fig. 4.6. In this color filter array there is only one color component in each pixel of the image @lee2001novel. The other two color components for the pixel must be interpolated from information gathered from its neighboring pixels @lee2001novel. After getting the Bayer images, the first green channel was isolated so that the images have empty and filled values ranging from 0 to 1023 arbitrary units. These images allow for the intensity of the pixels to be extracted and compared across multiple images. Images were taken of the FITC concentrations in a well plate with varying settings. Exposure time and brightness level were changed to see which sets of controls can best represent the trend between FITC concentration and pixel intensity. The final experiment cycled through nine different exposure times, ranging from 1 ms to 10000ms. For each exposure time, five images of the well plate were captured with a brightness level of 1. For mathematical analysis, a python script was used to save the green-channel intensities for each of the filled wells, along with two empty wells for comparison. At each well, the script took the mean intensity and standard deviation of a circle of pixels within a radius of 20 pixels, when given the corresponding center pixel location. These values were saved in an excel spreadsheet and then inputted into Matlab to find the mean and standard deviation of each concentration of FITC across five sets of images. The values were then plotted as intensity over FITC concentration in M. 

![Fig. 4.6 Bayer Color Filter Array](./images/bayer.png)

### Laser Speckle Contrast Imaging  {#lsci} 

In order to verify the analysis and LSCI computation of speckle images, a python script was used to create simulated speckle images. A simulated speckle pattern was generated using Python’s numpy library to make an NxN array of randomized, complex intensity values. Typical RGB images have intensities ranging from 0 to 255 arbitrary units. Given the simulated speckle array, a python processing script was used to calculate the phase and amplitude information of the image. Additionally, the script applied a circular, low pass filter in the fourier domain to the speckle pattern to enhance the quality of the image. An autocorrelation calculation was then applied to both the original and filtered speckle patterns using the fourier method described in Section 1.3 in order to quantify the temporal or spatial variations. Next, the speckle size was determined by finding the location in which the autocorrelation reaches the maximum of its peak on either side. The simulation was then run through a LSCI loop to calculate the K values as described in Section 3.3.

To take real-world speckle images for analysis, the modified box lid described in Section 2.3.2 was used. The laser module in Fig. 4.5a was affixed to the lid of the OpenIVIS box using a 3/8” 1/4-20 bolt along with the Arducam camera, as shown in Fig. 4.5b. In order to mimic movement that might be seen in a biological system, such as a vein with blood flow, a clear plastic tube was run through the center of the box. Diffuse liquid was pushed through the tube at varying flow rates by a kdScientific Syringe Pump and a 20 mL syringe with a Luer Lock. The area of the tube under study was placed directly under the Raspberry Pi camera and illuminated with the laser module. Images were taken using the corresponding python script and saved as .bmp files, and Bayer images as .npy arrays. Additionally, the green channel of the Bayer image were saved using a mask, as discussed in Section 2.3.2. The resulting images were processed using an additional python program to calculate the speckle size, intensity histogram and LSCI pattern. 

### Additional Capabilities {#additional-capabilities} 
In addition to fluorescence imaging and LSCI, the OpenIVIS system was verified for time lapse imaging. As discussed in the paper by Branning et. al @lee2024detection, the IVIS system can be used to image growth or changes in an organism or process over time. To verify this capability, 11 Tobacco Hornworms in individual, clear tubes were placed into the main section of the imaging box. The box was kept in a room set to 73oC to maintain healthy temperatures. The Neopixel LEDs were set to their full brightness in order to promote proper lighting conditions for growth. A python script was run through the Raspberry Pi that captures time lapsed images over a 10 day period. Images were set to be taken every five hours during that period. The images were then saved in a folder to be analyzed for hornworm growth. 

The OpenIVIS system’s versatile nature also provides opportunities for further scientific experiments. One possibility for the system's applications is the imaging of a degrading plant's Anthocyanin response. When plants decompose, they produce a fluorescent pigment called Anthocyanin. The Anthocyanin response can be visualized by taking the logarithm of the pixel intensities when excited by a red wavelength of light, over the intensity excited by a green wavelength of light, as shown in Eq. 5. In the OpenIVIS box, a lettuce leaf was placed in the main compartment. Using the Neopixel LED array, images were taken with red and green excitations of 653 nm and 520 nm respectively. Additionally, a long pass optical filter with a cutoff wavelength of 665 nm was placed below the camera in the system's filter holder to remove wavelengths below the red value. Images were taken three days apart for decomposition analysis. The images were then processed in python by applying Eq. 5 @zhang2023genome for each pixel location in the image.  

\begin{align}
A_{R} = log(\frac{I_{635nm}-I_{520nm}}{I_{635nm}+I_{520nm}}) \quad \text{(Eq.5)}
\end{align}
